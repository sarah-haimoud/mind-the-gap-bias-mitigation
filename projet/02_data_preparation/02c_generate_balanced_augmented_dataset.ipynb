{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c87fce",
   "metadata": {},
   "source": [
    "# Balanced Augmented Dataset Generation\n",
    "\n",
    "This notebook generates a balanced dataset by ensuring a 1:1 ratio between stereotypical and antistereotypical examples. The balanced dataset is designed to help mitigate bias during fine-tuning by preventing overrepresentation of stereotypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecaa3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, Dataset\n",
    "import random\n",
    "\n",
    "# Chemin vers le dataset que tu avais déjà préparé\n",
    "dataset_path = \"C:/Users/sarah/Documents/ERASMUS/NLP/augmented_dataset\"\n",
    "dataset = load_from_disk(dataset_path)\n",
    "\n",
    "# Fusionner train + test en un seul pool\n",
    "examples = list(dataset[\"train\"]) + list(dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813f69a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de stéréotypes  : 2106\n",
      "Nombre d'antistéréos : 6318\n"
     ]
    }
   ],
   "source": [
    "stereotypes = [ex[\"text\"] for ex in examples if ex[\"label\"] == 0]\n",
    "antistereotypes = [ex[\"text\"] for ex in examples if ex[\"label\"] == 1]\n",
    "\n",
    "print(f\"Nombre de stéréotypes  : {len(stereotypes)}\")\n",
    "print(f\"Nombre d'antistéréos : {len(antistereotypes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f46638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\biasenv\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "W0702 19:36:19.795707 22524 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\sarah\\biasenv\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\sarah\\biasenv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sarah\\biasenv\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#  Utilise t5-base \n",
    "paraphraser = pipeline(\"text2text-generation\", model=\"t5-base\", max_new_tokens=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a969d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_antis = []\n",
    "\n",
    "#  Choisis ici le nombre de phrases à paraphraser pour test rapide (ex: 100)\n",
    "subset = antistereotypes[:100]\n",
    "\n",
    "for text in subset:\n",
    "    try:\n",
    "        # \"paraphrase:\" est le prompt par défaut pour T5\n",
    "        result = paraphraser(f\"paraphrase: {text}\", num_return_sequences=3, do_sample=True, top_k=120)\n",
    "        for r in result:\n",
    "            paraphrased_antis.append(r[\"generated_text\"])\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur sur : {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede0234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder 1 version de chaque stéréotype\n",
    "final_examples = [{\"text\": text} for text in random.sample(stereotypes, k=len(subset))]\n",
    "\n",
    "# Ajouter les paraphrases antistéréotypes\n",
    "final_examples += [{\"text\": text} for text in paraphrased_antis]\n",
    "\n",
    "# Mélanger\n",
    "random.shuffle(final_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ddfb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4f492f91b9442f94edbd7aaff5d1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2218abbb6aba43328d314a2d29910ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset équilibré sauvegardé sous 'balanced_augmented_dataset'\n"
     ]
    }
   ],
   "source": [
    "# Convertir en Hugging Face Dataset\n",
    "final_dataset = Dataset.from_list(final_examples)\n",
    "\n",
    "# Découper train/test\n",
    "final_dataset = final_dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# Sauvegarder pour fine-tuning\n",
    "final_dataset.save_to_disk(\"balanced_augmented_dataset\")\n",
    "print(\"Dataset équilibré sauvegardé sous 'balanced_augmented_dataset'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biasenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
