{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4937c2bb",
   "metadata": {},
   "source": [
    "# Post-Fine-Tuning Evaluation\n",
    "\n",
    "This notebook evaluates the performance of the fine-tuned models on the StereoSet dataset. The goal is to assess the reduction of social bias using intrasentence and intersentence tasks, and to compare different fine-tuning strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a782982",
   "metadata": {},
   "source": [
    "# üìä √âvaluation post-fine-tuning (intrasentence)\n",
    "Ce notebook reprend le protocole du notebook `01_dataset_exploration.ipynb`, mais utilise le mod√®le **DistilBERT fine-tun√©** pour r√©√©valuer les biais sociaux sur le sous-ensemble **intrasentence** de StereoSet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5658b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Charger le mod√®le fine-tun√©\n",
    "model_path = \"finetuned_distilbert_stereo\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"dev.json\")\n",
    "with open(path, \"r\") as f:\n",
    "    full_data = json.load(f)\n",
    "\n",
    "intrasentence_examples = full_data[\"data\"][\"intrasentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    shift_logits = logits[:, :-1, :].squeeze(0)\n",
    "    shift_labels = inputs.input_ids[:, 1:].squeeze(0)\n",
    "    log_probs = F.log_softmax(shift_logits, dim=-1)\n",
    "    scores = log_probs[range(shift_labels.shape[0]), shift_labels]\n",
    "    return scores.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results_intra_post = []\n",
    "\n",
    "for ex in tqdm(intrasentence_examples):\n",
    "    target = ex[\"target\"]\n",
    "    bias = ex[\"bias_type\"]\n",
    "    context = ex[\"sentences\"][0][\"sentence\"]\n",
    "\n",
    "    scored = []\n",
    "    for s in ex[\"sentences\"]:\n",
    "        sent = s[\"sentence\"]\n",
    "        label = s[\"gold_label\"]\n",
    "        score = score_sentence(sent)\n",
    "        scored.append((label, score, sent))\n",
    "\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_label = scored[0][0]\n",
    "\n",
    "    results_intra_post.append({\n",
    "        \"bias_type\": bias,\n",
    "        \"target\": target,\n",
    "        \"top_label\": top_label,\n",
    "        \"all_scores\": scored,\n",
    "        \"context\": context\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = Counter([r[\"top_label\"] for r in results_intra_post])\n",
    "print(\"R√©sultats de classement des phrases (apr√®s fine-tuning) :\")\n",
    "for label, n in count.items():\n",
    "    print(f\" - {label} : {n}\")\n",
    "\n",
    "# Histogramme\n",
    "labels = list(count.keys())\n",
    "counts = list(count.values())\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(labels, counts, color=[\"red\", \"green\", \"gray\"])\n",
    "plt.title(\"Type de phrase pr√©f√©r√©e apr√®s fine-tuning (intrasentence)\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.xlabel(\"Type de phrase pr√©f√©r√©e\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "by_bias_type = defaultdict(int)\n",
    "total_by_type = defaultdict(int)\n",
    "\n",
    "for r in results_intra_post:\n",
    "    bias = r[\"bias_type\"]\n",
    "    total_by_type[bias] += 1\n",
    "    if r[\"top_label\"] == \"stereotype\":\n",
    "        by_bias_type[bias] += 1\n",
    "\n",
    "bias_types = sorted(total_by_type.keys())\n",
    "rates = [100 * by_bias_type[b] / total_by_type[b] for b in bias_types]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(bias_types, rates, marker='o', linestyle='-', color='red')\n",
    "plt.title(\"Taux de st√©r√©otypes pr√©f√©r√©s apr√®s fine-tuning (par type de biais)\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.xlabel(\"Bias Type\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925254eb",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion\n",
    "Le mod√®le fine-tun√© montre une √©volution dans ses pr√©f√©rences : on observe une l√©g√®re r√©duction du choix des phrases st√©r√©otyp√©es, en particulier sur certains types de biais. Cette √©tape valide l'int√©r√™t du fine-tuning sur des paires contre-st√©r√©otyp√©es pour att√©nuer les biais pr√©sents dans les mod√®les de langage pr√©-entra√Æn√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5218571",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This evaluation measures the effectiveness of different debiasing strategies. By analyzing stereotype preference scores across bias types, we can identify which training methods led to improved fairness and reduced stereotypical behavior in the model.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
