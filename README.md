# Mind the Gap – Bias Mitigation 

This project explores the detection and mitigation of **social biases** (gender, profession, race, religion) in small language models using the [StereoSet dataset](https://github.com/moinnadeem/stereoset).

I implemented and compared multiple fine-tuning strategies to reduce stereotypical completions generated by the model.


## Repository Structure


```
.
├── 01_dataset_exploration/         # Initial exploration of the StereoSet JSON dataset
├── 02_data_preparation/            # Preprocessing and data augmentation steps
├── 03_finetuning/
│   ├── baseline/                   # Standard fine-tuning without mitigation
│   ├── augmented/                  # Fine-tuning with augmented antistereotypical data
│   ├── balanced_augmented/         # Balanced dataset (1:1 stereotype vs antistereotype)
│   └── contrastive/                # Contrastive learning using positive/negative pairs
├── 04_evaluation/                  # Evaluation of biases after each training strategy
├── results/                        # outputs
├── other/                          # Additional or unused notebooks
├── requirements.txt
└── README.md
```

## Methods

We tested the following **bias mitigation strategies**:

| Strategy              | Description                                                                 |
| --------------------- | --------------------------------------------------------------------------- |
| **Baseline**          | Vanilla fine-tuning without mitigation                                      |
| **Augmented**         | Added multiple paraphrased antistereotypes per example using a T5 model     |
| **Balanced**          | One stereotype + several filtered antistereotypes per context (intentional imbalance) |
| **Contrastive**       | Trained on triplets (anchor, positive, negative)                            |
| **Adapters** (failed) | Attempted adapter-based mitigation (not integrated)                         |



## Evaluation

I used both:

* **Intrasentence bias** 
* **Intersentence bias** 

I provide:

* Accuracy & preference scores (based on StereoSet format)
* Visualizations of **worst stereotypical completions**
* Separate CSV files per evaluation type in `results/`

---

## Outputs

Visualisations with graphs
CSV files such as:

* `pires_cases_intrasentence_augmented.csv`
* `pires_cases_intersentence_contrastive.csv`
* `pires_cases_stereotypes_post.csv`

contain the worst predictions post-mitigation for qualitative inspection.


## Notes

* The models were based on `distilbert-base-uncased`
* All experiments were run in notebooks (see `03_finetuning/`)
* Some evaluations used hand-curated examples for deeper analysis

---

## Author

Sarah Haimoud – Erasmus student from France
